{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_mSj7jm31X9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf; tf.compat.v1.disable_eager_execution()\n","from keras import backend as K\n","from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Flatten, Lambda, Reshape\n","from keras.models import Model\n","from keras.losses import binary_crossentropy"],"metadata":{"id":"AEH_X1iinMcq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1jYKNDt3TFe"},"outputs":[],"source":["import os\n","from tqdm import tqdm\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.utils import img_to_array\n","from keras import regularizers\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import keras\n","from keras.optimizers import rmsprop_v2\n","import keras\n","from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D\n","from keras.models import Sequential, load_model\n","from keras.layers import LayerNormalization\n","from skimage import color\n","from skimage.transform import resize, rotate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u1NFH4hv3TFg"},"outputs":[],"source":["SIZE = 256\n","# /content/drive/MyDrive/CUHK Dataset/CUHK_testing_cropped_photos\n","image_path = '/content/drive/MyDrive/CUHK Dataset/CUHK_training_cropped_photos/'\n","img_array = []\n","\n","sketch_path = '/content/drive/MyDrive/CUHK Dataset/CUHK_training_cropped_sketches/'\n","sketch_array = []\n","\n","test_image_path = '/content/drive/MyDrive/CUHK Dataset/CUHK_testing_cropped_photos/'\n","test_img_array = []\n","\n","test_sketch_path = '/content/drive/MyDrive/CUHK Dataset/CUHK_testing_cropped_sketches/'\n","test_sketch_array = []\n","\n","# Image and their corresponding file names in a sorted manner based on their names\n","image_file = sorted(os.listdir(image_path))\n","sketch_file = sorted(os.listdir(sketch_path))\n","test_image_file = sorted(os.listdir(test_image_path))\n","test_sketch_file = sorted(os.listdir(test_sketch_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fhqn478u3TFh"},"outputs":[],"source":["def image_preprocessing(file_name, img_path, size):\n","  storage_array = []\n","  for img_file in tqdm(file_name):\n","    x = img_path + img_file\n","    img = (cv2.resize(cv2.imread(x,cv2.IMREAD_COLOR).astype('float32'),(SIZE,SIZE)))/255.0\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    storage_array.append(img)\n","    \n","  # Returning storage array where we have stored all our pre-processed images\n","  return np.array(storage_array)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhjvFDK83TFi"},"outputs":[],"source":["img_array = image_preprocessing(image_file, image_path, SIZE)\n","sketch_array = image_preprocessing(sketch_file, sketch_path, SIZE)\n","test_img_array = image_preprocessing(test_image_file, test_image_path, SIZE)\n","test_sketch_array = image_preprocessing(test_sketch_file, test_sketch_path, SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOq1u0683TFj"},"outputs":[],"source":["# Print the number of colored and sketch images present\n","print(\"Total number of Training Colored images:\",len(img_array))\n","print(\"Total number of Training sketch images:\",len(sketch_array))\n","print(\"Total number of Testing Colored images:\",len(test_img_array))\n","print(\"Total number of Testing sketch images:\",len(test_sketch_array))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1yp7i2w3TFk"},"outputs":[],"source":["# Converting the image arrays into numpy for easy processing \n","img_array_n = np.array(img_array)\n","sketch_array_n = np.array(sketch_array)\n","\n","test_img_array_n = np.array(test_img_array)\n","test_sketch_array_n = np.array(test_sketch_array)\n","\n","# Printing the shapes of the image \n","print(\"The shape of the train colored image array is:\", img_array_n.shape)\n","print(\"The shape of the train sketched image array is:\", sketch_array_n.shape)\n","\n","print(\"The shape of the test colored image array is:\", test_img_array_n.shape)\n","print(\"The shape of the test sketched image array is:\", test_sketch_array_n.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-h-5JLlM3TFl"},"outputs":[],"source":["# Plotting the training images to see\n","some_photos = np.concatenate([i for i in img_array_n[:5]],axis=1)\n","some_sketches = np.concatenate([i for i in sketch_array_n[:5]],axis=1)\n","plt.figure(figsize=(20,10))\n","plt.imshow(np.concatenate([some_photos,some_sketches]))\n","plt.axis(\"OFF\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32OREghN3TFl"},"outputs":[],"source":["# Plotting the testing images to see\n","some_photos = np.concatenate([i for i in test_img_array_n[:10]],axis=1)\n","some_sketches = np.concatenate([i for i in test_sketch_array_n[:10]],axis=1)\n","plt.figure(figsize=(20,10))\n","plt.imshow(np.concatenate([some_photos,some_sketches]))\n","plt.axis(\"OFF\")\n","plt.show()"]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = (img_array_n, sketch_array_n), (test_img_array_n, test_sketch_array_n)"],"metadata":{"id":"SRm_H9BNa8DT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape, y_train.shape, X_test.shape, y_test.shape"],"metadata":{"id":"mP4n4sVZa7_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Construction of Encoder"],"metadata":{"id":"NK8ETHFcqQ6n"}},{"cell_type":"code","source":["img_height   = X_train.shape[1]    # 256\n","img_width    = X_train.shape[2]    # 256\n","num_channels = X_train.shape[3]    # 3\n","\n","input_shape =  (img_height, img_width, num_channels)   # (256, 256, 3) \n","latent_dim = 16   # Dimension of the latent space"],"metadata":{"id":"AyO1Uvtfa77B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input = Input(shape=input_shape)\n","\n","encoder_conv = Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_input)\n","\n","encoder_conv = Conv2D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder_conv = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.BatchNormalization()(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder_conv = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder_conv = Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.BatchNormalization()(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder_conv = Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.BatchNormalization()(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder_conv = Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='relu')(encoder_conv)\n","encoder_conv = keras.layers.BatchNormalization()(encoder_conv)\n","encoder_conv = keras.layers.LeakyReLU()(encoder_conv)\n","\n","encoder = Flatten()(encoder_conv)\n","\n","mu = Dense(latent_dim)(encoder)\n","sigma = Dense(latent_dim)(encoder)"],"metadata":{"id":"5XN5Rd-J1awW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## To determine the values in the latent space layer"],"metadata":{"id":"LbMAdoJOswi6"}},{"cell_type":"code","source":["def compute_latent(x):\n","    mu, sigma = x\n","    batch = K.shape(mu)[0]\n","    dim = K.int_shape(mu)[1]\n","    eps = K.random_normal(shape=(batch,dim))\n","    return mu + K.exp(sigma/2)*eps"],"metadata":{"id":"eBDmbpdDa7z1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reparameterization "],"metadata":{"id":"IC5_JORDtCtD"}},{"cell_type":"code","source":["latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])"],"metadata":{"id":"v6m5rwXrtGMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_shape = K.int_shape(encoder_conv)"],"metadata":{"id":"_cYXnonitIad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_shape"],"metadata":{"id":"lg38bxQ2tIXF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Construction of Decoder"],"metadata":{"id":"ARDCdDa3tfHW"}},{"cell_type":"code","source":["decoder_input = Input(shape=(latent_dim,))\n","\n","decoder = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)\n","\n","decoder = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(decoder)\n","\n","decoder_conv = Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same', activation='relu')(decoder)\n","decoder_conv = keras.layers.Dropout(0.1)(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","decoder_conv = keras.layers.Dropout(0.1)(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","decoder_conv = keras.layers.LeakyReLU()(decoder_conv)\n","\n","decoder_conv = Conv2DTranspose(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_conv)\n","\n","decoder_conv =  Conv2DTranspose(filters=num_channels, kernel_size=3, padding='same', activation='sigmoid')(decoder_conv)"],"metadata":{"id":"yCWWi7arCEMe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Connecting the encoder and decoder"],"metadata":{"id":"3GRVJZeduYKJ"}},{"cell_type":"code","source":["encoder = Model(encoder_input, latent_space)\n","decoder = Model(decoder_input, decoder_conv)"],"metadata":{"id":"LKIONQGhtIQb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The output of vae model is the output of decoder in which its input is taken from the output of encoder"],"metadata":{"id":"jJRfHwdrujV5"}},{"cell_type":"code","source":["vae = Model(encoder_input, decoder(encoder(encoder_input)))"],"metadata":{"id":"VZTQGrSntINV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summary of autoencoder"],"metadata":{"id":"GitQxWv2u6MK"}},{"cell_type":"code","source":["vae.summary()"],"metadata":{"id":"kDwccI5MtIKC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summary of encoder"],"metadata":{"id":"ObLnbSuKvC7d"}},{"cell_type":"code","source":["encoder.summary()"],"metadata":{"id":"O4gyLbEHtIHG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Summary of decoder"],"metadata":{"id":"ZfJlMMgtvIir"}},{"cell_type":"code","source":["decoder.summary()"],"metadata":{"id":"ifjgupDctIER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Defining loss function"],"metadata":{"id":"6T6TAWqAvld0"}},{"cell_type":"code","source":["def kl_reconstruction_loss(true, pred):    # Reconstruction loss\n","    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred)) * img_width * img_height    \n","    \n","    # KL divergence loss\n","    kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n","    kl_loss = K.sum(kl_loss, axis=-1)\n","    kl_loss *= -0.5    \n","    \n","    # Total loss = 50% rec + 50% KL divergence loss\n","    return K.mean(reconstruction_loss + kl_loss)"],"metadata":{"id":"pVHQkO-etIA9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compiling the model"],"metadata":{"id":"ePowMUsLv8V_"}},{"cell_type":"code","source":["vae.compile(optimizer='adam', loss=kl_reconstruction_loss)"],"metadata":{"id":"yyRXU4L_v4Sy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the model"],"metadata":{"id":"FvFHeYBCwGru"}},{"cell_type":"code","source":["history = vae.fit(x=X_train, y=y_train, epochs=100, batch_size=16, validation_data=(X_test,y_test))"],"metadata":{"id":"JGgjsN_Hv_9A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Loss value of both train and test data"],"metadata":{"id":"ztCRwHuVwfgU"}},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.legend(['Training loss', 'Validation loss'])\n"],"metadata":{"id":"XLNu58n7v_5p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Displaying latent space"],"metadata":{"id":"l5RPQcwxw2GI"}},{"cell_type":"code","source":["encoded = encoder.predict(X_train)"],"metadata":{"id":"Op1eofxqv_3K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decoding data points in latent space"],"metadata":{"id":"A0oQ73OOxSrE"}},{"cell_type":"code","source":["def display_image_sequence(x_start,y_start,x_end,y_end,no_of_imgs):\n","    x_axis = np.linspace(x_start,x_end,no_of_imgs)\n","    y_axis = np.linspace(y_start,y_end,no_of_imgs)\n","    \n","    x_axis = x_axis[:, np.newaxis]\n","    y_axis = y_axis[:, np.newaxis]\n","    \n","    new_points = np.hstack((x_axis, y_axis))\n","\n","    print(new_points.shape)\n","\n","    new_images = decoder.predict(new_points)\n","    print(new_images.shape)\n","    \n","    new_images = new_images.reshape(new_images.shape[0], new_images.shape[1], new_images.shape[2], new_images.shape[3])\n","    \n","    # Display some images\n","    fig, axes = plt.subplots(ncols=no_of_imgs, sharex=False, sharey=True, figsize=(20, 7))\n","    counter = 0\n","    for i in range(no_of_imgs):\n","        axes[counter].imshow(new_images[i], cmap='gray')\n","        axes[counter].get_xaxis().set_visible(False)\n","        axes[counter].get_yaxis().set_visible(False)\n","        counter += 1\n","    plt.show()"],"metadata":{"id":"8IQe3QGHv_ud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","some_photos = []\n","sketch_photos = []\n","for i in range(9, 90, 7):\n","  some_photos.append(y_test[i])\n","  sketch_photos.append(vae.predict(X_test)[i])\n","\n","\n","X = np.concatenate(some_photos, axis=1)\n","Y = np.concatenate(sketch_photos, axis=1)\n","\n","plt.figure(figsize=(20,10))\n","plt.imshow(np.concatenate([X,Y]))\n","plt.axis(\"OFF\")\n","\n","plt.show()"],"metadata":{"id":"IPkc57OYX8dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(80,90):\n","  img_no = i\n","  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(5, 3))\n","  axes[0].imshow(X_test[img_no])\n","  axes[1].imshow(y_test[img_no])\n","  axes[2].imshow(vae.predict(X_test)[img_no])\n","  \n","  fig.tight_layout()"],"metadata":{"id":"vb543q5JDgaQ"},"execution_count":null,"outputs":[]}]}